# -*- coding: utf-8 -*-
"""assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CauF3ZgaSOcI2TpME-bF9DJvfTymHdiU
"""

import nltk
import spacy
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

text="Semantic communication is viewed as a revolutionary paradigm that can potentially transform how we design and operate wireless communication systems. However, despite a recent surge of research activities in this area, remarkably, the research landscape is still limited in at least three ways. First and foremost, the definition of a “semantic communication system” is ambiguous and varies widely between different studies. This lack of consensus makes it challenging to develop rigorous and scalable frameworks for building semantic communication networks. Secondly, current approaches to building semantic communication networks are limited by their reliance on data-driven and information-driven AI-augmented networks. These networks remain “tied” to the data, which limits their ability to perform versatile logic. In contrast, knowledge-driven and reasoning-driven AI-native networks would allow for more flexible and powerful communication capabilities. However, there is currently a lack of technical foundations to support such networks. Thirdly, the concept of “semantic representation” is not well understood yet, and its role in embedding meaning and structure in data transferred across wireless network is still a subject of active research. The development of semantic representations that are minimalist, generalizable, and efficient is critical to enabling the transmitter and receiver to generate content via a minimally semantic representation. To address these limitations, in this tutorial, we propose the first rigorous and holistic vision of an end-to-end semantic communication network that is founded on novel concepts from artificial intelligence (AI), causal reasoning, transfer learning, and minimum description length theory. We first discuss how the design of semantic communication networks requires a move from data-driven AI-augmented networks, in which wireless networks remain “tied” to data, towards reasoning-driven AI-native networks which can perform versatile logic and generalizable intelligence. We then distinguish the concept of semantic communications from several other approaches that have been conflated with it. We opine that building effective and efficient semantic communication systems necessitates surpassing the creation of new encoder and decoder types at the transmitter/receiver side, or developing an “AI for wireless” framework that only extracts application features or fine-tunes wireless protocols/algorithms. Then, we identify the main tenets that are needed to build an end-to-end semantic communication network. Among those building blocks of a semantic communication network, we highlight the necessity of creating semantic representations of data that satisfy the key properties of minimalism, generalizability, and efficiency so as to faithfully represent the data and enable the transmitter and receiver to do more with less. We then explain how those representations can form the basis of a so-called semantic language that will allow a transmitter and receiver to communicate at a semantic level. We then concretely define the concept of reasoning by investigating the fundamentals of causal representation learning and their role in designing reasoning-driven semantic communication networks. For such reasoning-driven networks, we propose novel and essential semantic communication key performance indicators (KPIs) and metrics, including new “reasoning capacity” measures that could surpass Shannon’s bound to capture the imminent convergence of computing and communication resources. Finally, we explain how semantic communications can be scaled to large-scale networks such as 6G and beyond cellular networks. In a nutshell, we expect this tutorial to provide a unified and self-contained reference on how to properly build, design, analyze, and deploy next-generation semantic communication networks."

tokens = word_tokenize(text.lower())
tokens = [word for word in tokens if word not in stopwords.words('english') and word not in string.punctuation]
print(tokens[:50])

!pip install nltk spacy gensim transformers sentence-transformers --quiet
!python -m nltk.downloader punkt stopwords
!python -m spacy download en_core_web_sm

stop_words = set(stopwords.words('english'))
nlp = spacy.load("en_core_web_sm")

def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]
    doc = nlp(" ".join(tokens))
    lemmatized = [token.lemma_ for token in doc if token.lemma_ not in stop_words]
    return lemmatized

lemmatized_tokens = preprocess_text(text)
print("Lemmatized Tokens:", lemmatized_tokens[:50])

from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import pipeline
documents = [text]

vectorizer = TfidfVectorizer(stop_words='english', max_features=15)
X = vectorizer.fit_transform(documents)
keywords = vectorizer.get_feature_names_out()

print("Top Keywords:", keywords)

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

summary = summarizer(text, max_length=200, min_length=50, do_sample=False)
print("Summary:\n", summary[0]['summary_text'])

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')

sentences = [
    "Semantic communication is a revolutionary paradigm.",
    "Shannon’s theory focuses on signal transmission, not meaning.",
]

embeddings = model.encode(sentences, convert_to_tensor=True)
similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1])

print("Semantic Similarity Score:", similarity.item())

